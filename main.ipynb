{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN to generate images using CelebA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 23:45:44.180217: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-05 23:45:44.189115: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 23:45:44.199906: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 23:45:44.202936: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 23:45:44.210985: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 23:45:44.776467: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as ts \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import zipfile\n",
    "import gdown "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "\n",
    "# Set user and dataset information\n",
    "USER = 'jessicali9530'\n",
    "DATASET = 'celeba-dataset'\n",
    "\n",
    "# Define the dataset path\n",
    "data_path = 'celeba_gan'  # Ensure this matches the intended path\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "!kaggle datasets download -d {USER}/{DATASET} -p {data_path}\n",
    "\n",
    "# Check if the zip file exists\n",
    "dataset_zip_path = os.path.join(data_path, f'{DATASET}.zip')\n",
    "if os.path.exists(dataset_zip_path):\n",
    "    # Unzip the dataset\n",
    "    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_path)\n",
    "    # Remove the zip file\n",
    "    os.remove(dataset_zip_path)\n",
    "    print('🚀 Done!')\n",
    "else:\n",
    "    print(f\"Error: File '{dataset_zip_path}' not found. Please check if the dataset was downloaded correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722915952.966012  112112 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722915952.987964  112112 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722915952.988211  112112 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722915952.989812  112112 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722915952.989839  112112 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722915952.989850  112112 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722915953.103196  112112 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1722915953.103245  112112 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 23:45:53.103255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1722915953.103284  112112 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 23:45:53.103301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:07:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create an image dataset\n",
    "dataset= keras.preprocessing.image_dataset_from_directory ('celeba_gan', # path to images\n",
    "                                                           label_mode=None, # no label\n",
    "                                                           image_size=(64,64), # image size\n",
    "                                                           batch_size=32)\n",
    "# normalizing the image\n",
    "dataset = dataset.map(lambda x: x/255.0)\n",
    "# show a sample\n",
    "for sample in dataset:\n",
    "    plt.axis(\"off\") # turn off the axis label\n",
    "    plt.imshow((sample.numpy() * 255).astype(\"int32\") [0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saeid23/anaconda3/envs/gan/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,555,073</span> (5.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,555,073\u001b[0m (5.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,553,281</span> (5.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,553,281\u001b[0m (5.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow import Tensor\n",
    "\n",
    "# Hyper parameters\n",
    "input_shape = (64, 64, 3)\n",
    "initial_feature_map = 64\n",
    "num_block = 4\n",
    "def conv_block (img: Tensor, filter: int , apply_batch : bool = True):\n",
    "    x=layers.Conv2D(filters=filter, kernel_size=3, strides=2, padding='same')(img)\n",
    "    if apply_batch:\n",
    "        x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)  # Adjusted alpha to match common practice\n",
    "    x = layers.Dropout(0.25)(x)  # shape: (batch, 64, H/2, W/2)\n",
    "    return x\n",
    "# Discriminator model\n",
    "def Discriminator(input_shape: tuple= (64, 64, 3), initial_feature_map : int = 64, num_block : int = 4):\n",
    "    ds_input = layers.Input(shape=input_shape)\n",
    "    for idx  in range(num_block):\n",
    "        if idx==0:\n",
    "            x = conv_block (ds_input, initial_feature_map * (2**idx), apply_batch= False)\n",
    "        else:\n",
    "            x = conv_block (x, initial_feature_map * (2**idx), apply_batch= True)\n",
    "    \n",
    "    # Global Max Pooling\n",
    "    x = layers.GlobalMaxPooling2D()(x)  # shape: (batch, 512)\n",
    "    latent_dim =x.shape[-1]\n",
    "    # Dense Layer\n",
    "    dense_output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Create and return the model\n",
    "    ds_model = Model(inputs=ds_input, outputs=dense_output)\n",
    "    return ds_model, latent_dim\n",
    "\n",
    "# Example usage\n",
    "discriminator, latent_dim = Discriminator(input_shape = input_shape, initial_feature_map = initial_feature_map, num_block = num_block)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,202,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">867</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │     \u001b[38;5;34m4,202,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,040\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │           \u001b[38;5;34m867\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,772,483</span> (22.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,772,483\u001b[0m (22.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,771,523</span> (22.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,771,523\u001b[0m (22.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generator model\n",
    "def upconv_block(x : Tensor, filters: int):\n",
    "    \"\"\"Defines an upsampling convolutional block with optional batch normalization.\"\"\"\n",
    "    x = layers.Conv2DTranspose(filters=filters, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def Generator(latent_dim: int,\n",
    "               output_shape: tuple = (64, 64, 3), \n",
    "               initial_feature_map: int = 64, \n",
    "               num_block: int = 4):\n",
    "    \n",
    "    gen_input = layers.Input(shape=(latent_dim,))\n",
    "    # reshape latent vector into small image\n",
    "    x = layers.Dense(output_shape[0]// (2** num_block) * output_shape[1]// (2** num_block) * latent_dim)(gen_input)\n",
    "    x=layers.Reshape((output_shape[0]// (2** num_block),\n",
    "                      output_shape[1]// (2** num_block), \n",
    "                      latent_dim))(x)\n",
    "    # Upsample through several blocks\n",
    "    for idx in range(num_block):\n",
    "        x = upconv_block (x , latent_dim// (2** (idx +1)) )    \n",
    "    # Output layer to generate the final image\n",
    "    x = layers.Conv2D(filters=output_shape[-1], kernel_size=3, strides=1, padding='same', activation='sigmoid')(x)\n",
    "    gen_model = Model(inputs= gen_input, outputs = x)\n",
    "    return gen_model\n",
    "generator = Generator(latent_dim, input_shape, initial_feature_map, num_block)\n",
    "generator.summary()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN model\n",
    "import tensorflow as tf\n",
    "class DCGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super (DCGAN, self).__init__()\n",
    "        self.discriminator= discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "    def compile(self, ds_optimizer, gen_optimizer, loss_fn):\n",
    "        super (DCGAN, self).compile()\n",
    "        self.ds_optimizer = ds_optimizer\n",
    "        self.gen_optimizer = gen_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.ds_loss_metric = keras.metrics.Mean(name = 'ds_loss')\n",
    "        self.gen_loss_metric = keras.metrics.Mean(name = 'gen_loss')\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.ds_loss_metric, self.gen_loss_metric]\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        batch_size = real_images.shape[0]\n",
    "        # sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        # Generate a fake image using the random selected points from the latent space\n",
    "        generated_images = self.generator (self.latent_dim, training=True)\n",
    "        # concatenate them with the real images\n",
    "        real_fake_images = tf.concat([generated_images , real_images], axis = 0)\n",
    "        # labels -> fake images: 1, real images: 0\n",
    "        labels = tf.concat([tf.ones(batch_size,1), tf.zeros(batch_size,1)], axis = 0)\n",
    "        # Add random noise to labels to increase the models stability\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "        \n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as ds_tape:\n",
    "            predictions = self.discriminator(real_fake_images)\n",
    "            ds_loss = self.loss_fn(labels, predictions)\n",
    "        grads_of_discriminator= ds_tape.gradient(ds_loss, self.discriminator.trainable_weights)\n",
    "        self.ds_optimizer.apply_gradients(zip(grads_of_discriminator, self.discriminator.trainable_weights))\n",
    "        self.ds_loss_metric.update_state(ds_loss)\n",
    "        # Train the Generator\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            fake_predictions = self.discriminator(generated_images)\n",
    "            gen_loss = self.loss_fn(misleading_labels, fake_predictions)\n",
    "        grads_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_weights)\n",
    "        self.gen_optimizer.apply_gradients(zip (grads_of_generator,  self.generator.trainable_weights))\n",
    "        self.gen_loss_metric.update_state(gen_loss)\n",
    "        return {\n",
    "            \"ds_loss\" : self.ds_loss_metric.result (),\n",
    "            \"gen_loss\" : self.gen_loss_metric.result(),\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
