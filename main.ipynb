{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN to generate images using CelebA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as ts \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import zipfile\n",
    "import gdown "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.7/82.7 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bleach\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.8/162.8 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2023.7.22 in /home/saeid23/.local/lib/python3.10/site-packages (from kaggle) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil in /home/saeid23/.local/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /home/saeid23/.local/lib/python3.10/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/saeid23/.local/lib/python3.10/site-packages (from kaggle) (4.66.4)\n",
      "Requirement already satisfied: urllib3 in /home/saeid23/.local/lib/python3.10/site-packages (from kaggle) (2.2.2)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.2/78.2 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/saeid23/.local/lib/python3.10/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/saeid23/.local/lib/python3.10/site-packages (from requests->kaggle) (3.7)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105805 sha256=21d8ae98200a11db1330bced4a97478cc8e93f9af3b4925b9b9b6e64b41d8801\n",
      "  Stored in directory: /home/saeid23/.cache/pip/wheels/9f/af/22/bf406f913dc7506a485e60dce8143741abd0a92a19337d83a3\n",
      "Successfully built kaggle\n",
      "Installing collected packages: webencodings, text-unidecode, python-slugify, bleach, kaggle\n",
      "Successfully installed bleach-6.1.0 kaggle-1.6.17 python-slugify-8.0.4 text-unidecode-1.3 webencodings-0.5.1\n",
      "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/celeba-dataset\n",
      "License(s): other\n",
      "Downloading celeba-dataset.zip to celeba_gan\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.33G/1.33G [02:52<00:00, 9.21MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.33G/1.33G [02:52<00:00, 8.26MB/s]\n",
      "ğŸš€ Done!\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "\n",
    "# Set user and dataset information\n",
    "USER = 'jessicali9530'\n",
    "DATASET = 'celeba-dataset'\n",
    "\n",
    "# Define the dataset path\n",
    "data_path = 'celeba_gan'  # Ensure this matches the intended path\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "!kaggle datasets download -d {USER}/{DATASET} -p {data_path}\n",
    "\n",
    "# Check if the zip file exists\n",
    "dataset_zip_path = os.path.join(data_path, f'{DATASET}.zip')\n",
    "if os.path.exists(dataset_zip_path):\n",
    "    # Unzip the dataset\n",
    "    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_path)\n",
    "    # Remove the zip file\n",
    "    os.remove(dataset_zip_path)\n",
    "    print('ğŸš€ Done!')\n",
    "else:\n",
    "    print(f\"Error: File '{dataset_zip_path}' not found. Please check if the dataset was downloaded correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files.\n"
     ]
    }
   ],
   "source": [
    "# create an image dataset\n",
    "dataset= keras.preprocessing.image_dataset_from_directory ('celeba_gan', # path to images\n",
    "                                                           label_mode=None, # no label\n",
    "                                                           image_size=(64,64), # image size\n",
    "                                                           batch_size=32)\n",
    "# normalizing the image\n",
    "dataset = dataset.map(lambda x: x/255.0)\n",
    "\n",
    "# show a sample\n",
    "for sample in dataset:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((sample.numpy() * 255).astype(\"int32\") [0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
